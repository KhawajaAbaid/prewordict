{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-06-17T05:01:44.046698Z","iopub.status.busy":"2022-06-17T05:01:44.046171Z","iopub.status.idle":"2022-06-17T05:01:50.127800Z","shell.execute_reply":"2022-06-17T05:01:50.126862Z","shell.execute_reply.started":"2022-06-17T05:01:44.046603Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","from numpy.linalg import norm\n","from sklearn.preprocessing import normalize\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","from wordcloud import WordCloud\n","import os\n","import shutil\n","import pathlib\n","import gc\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-06-17T05:01:50.129978Z","iopub.status.busy":"2022-06-17T05:01:50.129396Z","iopub.status.idle":"2022-06-17T05:01:50.135381Z","shell.execute_reply":"2022-06-17T05:01:50.134467Z","shell.execute_reply.started":"2022-06-17T05:01:50.129947Z"},"trusted":true},"outputs":[],"source":["# root dir to store the zip file of the whole output folder which serves as the base directory\n","# for all the things output by the script\n","root_dir = pathlib.Path(\"/kaggle/working/\")\n","base_dir = pathlib.Path(\"/kaggle/working/output/\")\n","os.makedirs(base_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-06-17T05:01:55.042992Z","iopub.status.busy":"2022-06-17T05:01:55.041995Z","iopub.status.idle":"2022-06-17T05:02:29.104601Z","shell.execute_reply":"2022-06-17T05:02:29.103485Z","shell.execute_reply.started":"2022-06-17T05:01:55.042935Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-17 05:02:25.975503: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"]},{"name":"stdout","output_type":"stream","text":["25\n"]}],"source":["articles_dataset = tf.data.Dataset.from_tensor_slices((pd.read_csv(\"/kaggle/input/medium-articles/medium_articles.csv\")['text']).values)\n","articles_dataset = articles_dataset.batch(8000)\n","total_batches = len(articles_dataset)\n","print(total_batches)"]},{"cell_type":"markdown","metadata":{},"source":["## We've got 25 batches of length 8000 each but we have about 190K or 190K+ artciles so the first 24 batches take up 192K articles hence it's obvious that the last batch would be around ~1K texts or less, which may not be suitable for us, but generate word clouds from it anyway."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-06-17T05:02:42.194683Z","iopub.status.busy":"2022-06-17T05:02:42.194189Z","iopub.status.idle":"2022-06-17T05:47:23.718419Z","shell.execute_reply":"2022-06-17T05:47:23.717593Z","shell.execute_reply.started":"2022-06-17T05:02:42.194638Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17062ca0a09443acb54cce2dd4704478","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Processing batch 1 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 96452\n","\tSaving /kaggle/working/output/batch0/words_summed_tfidf_batch_0.csv to disk...\n","\tSaving /kaggle/working/output/batch0/sorted_words_summed_tfidf_batch_0.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d783b9613efd4ddaa712c68caee849df","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 0. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 2 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 101738\n","\tSaving /kaggle/working/output/batch1/words_summed_tfidf_batch_1.csv to disk...\n","\tSaving /kaggle/working/output/batch1/sorted_words_summed_tfidf_batch_1.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"546f2d7e3440410fb90f3f6f06eba5d6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 1. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 3 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 100347\n","\tSaving /kaggle/working/output/batch2/words_summed_tfidf_batch_2.csv to disk...\n","\tSaving /kaggle/working/output/batch2/sorted_words_summed_tfidf_batch_2.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9add20b84714fe29b752517ecea5aaf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 2. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 4 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 99737\n","\tSaving /kaggle/working/output/batch3/words_summed_tfidf_batch_3.csv to disk...\n","\tSaving /kaggle/working/output/batch3/sorted_words_summed_tfidf_batch_3.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5251fa564a34764a8a8e6208b0eb485","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 3. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 5 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 100453\n","\tSaving /kaggle/working/output/batch4/words_summed_tfidf_batch_4.csv to disk...\n","\tSaving /kaggle/working/output/batch4/sorted_words_summed_tfidf_batch_4.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96f223a845584bdca68eb1c9c2e36c7e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 4. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 6 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 103910\n","\tSaving /kaggle/working/output/batch5/words_summed_tfidf_batch_5.csv to disk...\n","\tSaving /kaggle/working/output/batch5/sorted_words_summed_tfidf_batch_5.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"776c31b9801941d68afcae6afdd839f1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 5. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 7 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 101115\n","\tSaving /kaggle/working/output/batch6/words_summed_tfidf_batch_6.csv to disk...\n","\tSaving /kaggle/working/output/batch6/sorted_words_summed_tfidf_batch_6.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"863178a92ea944e78b1c80b61551bad2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 6. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 8 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 99650\n","\tSaving /kaggle/working/output/batch7/words_summed_tfidf_batch_7.csv to disk...\n","\tSaving /kaggle/working/output/batch7/sorted_words_summed_tfidf_batch_7.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5e7a981d80041c3b6b3cc58e167e3a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 7. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 9 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 101513\n","\tSaving /kaggle/working/output/batch8/words_summed_tfidf_batch_8.csv to disk...\n","\tSaving /kaggle/working/output/batch8/sorted_words_summed_tfidf_batch_8.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8aa14f537ae4408ea27972764c9c5ac9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 8. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 10 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 94883\n","\tSaving /kaggle/working/output/batch9/words_summed_tfidf_batch_9.csv to disk...\n","\tSaving /kaggle/working/output/batch9/sorted_words_summed_tfidf_batch_9.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad18b971faeb4ed9ad37e67df6e1c05c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 9. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 11 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 95785\n","\tSaving /kaggle/working/output/batch10/words_summed_tfidf_batch_10.csv to disk...\n","\tSaving /kaggle/working/output/batch10/sorted_words_summed_tfidf_batch_10.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92ed82f3987e45da956234005fb89aa5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 10. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 12 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 99021\n","\tSaving /kaggle/working/output/batch11/words_summed_tfidf_batch_11.csv to disk...\n","\tSaving /kaggle/working/output/batch11/sorted_words_summed_tfidf_batch_11.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96c170c63a864e7cbbe3d652571d7185","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 11. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 13 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 86298\n","\tSaving /kaggle/working/output/batch12/words_summed_tfidf_batch_12.csv to disk...\n","\tSaving /kaggle/working/output/batch12/sorted_words_summed_tfidf_batch_12.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"628c6e02e3b941149ca2eaadce4ae871","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 12. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 14 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 100489\n","\tSaving /kaggle/working/output/batch13/words_summed_tfidf_batch_13.csv to disk...\n","\tSaving /kaggle/working/output/batch13/sorted_words_summed_tfidf_batch_13.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1f6afb21d314d4aaab10ddf1d05c294","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 13. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 15 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 98249\n","\tSaving /kaggle/working/output/batch14/words_summed_tfidf_batch_14.csv to disk...\n","\tSaving /kaggle/working/output/batch14/sorted_words_summed_tfidf_batch_14.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"026045aed4ba4eea8fd3a3b42d8915d0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 14. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 16 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 105084\n","\tSaving /kaggle/working/output/batch15/words_summed_tfidf_batch_15.csv to disk...\n","\tSaving /kaggle/working/output/batch15/sorted_words_summed_tfidf_batch_15.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da2bcb1857194382b1d4fe20d4214989","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 15. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 17 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 96444\n","\tSaving /kaggle/working/output/batch16/words_summed_tfidf_batch_16.csv to disk...\n","\tSaving /kaggle/working/output/batch16/sorted_words_summed_tfidf_batch_16.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e47a86faf403469abebfd46e0914b89a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 16. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 18 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 106302\n","\tSaving /kaggle/working/output/batch17/words_summed_tfidf_batch_17.csv to disk...\n","\tSaving /kaggle/working/output/batch17/sorted_words_summed_tfidf_batch_17.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31ffd760b60f45039649b3de18705e2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 17. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 19 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 115056\n","\tSaving /kaggle/working/output/batch18/words_summed_tfidf_batch_18.csv to disk...\n","\tSaving /kaggle/working/output/batch18/sorted_words_summed_tfidf_batch_18.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b29cf48faa70497e88cd1e528d285d5c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 18. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 20 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 112884\n","\tSaving /kaggle/working/output/batch19/words_summed_tfidf_batch_19.csv to disk...\n","\tSaving /kaggle/working/output/batch19/sorted_words_summed_tfidf_batch_19.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"072e6b35d2444da5b77cf19bdaff065d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 19. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 21 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 121007\n","\tSaving /kaggle/working/output/batch20/words_summed_tfidf_batch_20.csv to disk...\n","\tSaving /kaggle/working/output/batch20/sorted_words_summed_tfidf_batch_20.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7edd8e2c56f24239ab6b87f951105696","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 20. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 22 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 112130\n","\tSaving /kaggle/working/output/batch21/words_summed_tfidf_batch_21.csv to disk...\n","\tSaving /kaggle/working/output/batch21/sorted_words_summed_tfidf_batch_21.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9fc8eef80f947e6a691c5050334131c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 21. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 23 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 115608\n","\tSaving /kaggle/working/output/batch22/words_summed_tfidf_batch_22.csv to disk...\n","\tSaving /kaggle/working/output/batch22/sorted_words_summed_tfidf_batch_22.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee504a7fe9294b64bd7cce47ae4525a4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 22. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 24 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 98380\n","\tSaving /kaggle/working/output/batch23/words_summed_tfidf_batch_23.csv to disk...\n","\tSaving /kaggle/working/output/batch23/sorted_words_summed_tfidf_batch_23.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4098969b71454fed9403288ac734740f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 23. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n","\n","Processing batch 25 / 25\n","\tMaking directories...\n","\t\tSuccessfully created required directories.\n","\tPerforming vectorization x...\n","\t\tSuccessfully vectorized x.\n","\tTotal Words -> 18789\n","\tSaving /kaggle/working/output/batch24/words_summed_tfidf_batch_24.csv to disk...\n","\tSaving /kaggle/working/output/batch24/sorted_words_summed_tfidf_batch_24.csv to disk...\n","\tApplying SVD...\n","\t\tSuccessfully applied SVD.\n","\tNormalizing shrunk matrix...\n","\t\tTarget normalized.\n","\tClustering words into groups...\n","\t\tSuccessfully Clustered!\n","\tGenerating word cloud images for clusters... \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6a8fed6d5f94e09ab938f5207e4ad31","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tYay! Everything went well for batch 24. Onto the next one!\n","\n","\tClearning up memory for next iteration so we dont run out of memory...\n"]},{"data":{"text/plain":["'/kaggle/working/output.zip'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#Collected all the code in one cell to save memory consumption\n","#------------------\n","\n","\n","def rank_words_by_tfidf(indices, words_list):\n","    \"\"\"Ranks the words, specified by indices which are sent in by \"cluster_to_cloud\"\n","    function. Ranking is based on the summed tfidf score \"\"\"\n","    \n","    summed_tfidf = np.asarray(tfidf_matrix[indices].sum(axis=0))\n","    data = {\"Words\": words_list,\n","           \"Summed_TFIDF\": summed_tfidf}\n","    return pd.DataFrame(data).sort_values(\"Summed_TFIDF\", ascending=False)\n","\n","\n","#-------------------\n","\n","\n","def cluster_to_cloud(df_cluster, max_words=15, cluster_num=0, words_list=None, batch_num=0, save_dir=None):\n","    \"\"\"Generates a word cloud image using the top 15 words \n","    (which are ranked by their tfidf score) in the given cluster\"\"\"\n","    \n","    indices = df_cluster.Index.values\n","    df_ranked_words_all = rank_words_by_tfidf(indices, words_list)\n","    df_ranked_words_in_cloud = df_ranked_words_all[:max_words]\n","    df_ranked_words_remaining = df_ranked_words_all[max_words:]\n","    \n","    filename = save_dir / f\"cluster_{cluster_num}_words_batch_{batch_num}.csv\"\n","    df_ranked_words_remaining.to_csv(filename, index=False)\n","    words_to_score = {word:score\n","                     for word, score in df_ranked_words_in_cloud.values}    \n","    cloud_generator = WordCloud(background_color=\"white\",\n","                               random_state=1, width=2000, height=1000)\n","    wordcloud_image = cloud_generator.fit_words(words_to_score)\n","    return wordcloud_image\n","\n","\n","#------------------\n","\n","\n","def vectorizeX(batch):\n","    \"\"\"Vectorizes the texts,generates the TFIDF matrix\n","    and returns TFIDF matrix, words, and sorted words TFIDF dataframe.\n","    X in the function names stands for eXtra, as it performs and returns some extra things\n","    also in all honesty, it's more because it's sounds cool this way. No judging, okay?\"\"\"\n","    \n","    tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n","    tfidf_matrix = tfidf_vectorizer.fit_transform(batch).toarray()\n","    words = tfidf_vectorizer.get_feature_names_out()\n","    words_tfidf_df = pd.DataFrame({\"Words\": words, \"Summed_TFIDF\": tfidf_matrix.sum(axis=0)})\n","    sorted_words_tfidf_df = words_tfidf_df.sort_values(by=\"Summed_TFIDF\", ascending=False)\n","    \n","    return words, tfidf_matrix, words_tfidf_df, sorted_words_tfidf_df\n","\n","\n","#-------------------\n","\n","\n","def clusterItUp(shrunk_norm_matrix, batch_num=0):\n","    \"\"\"Takes the normalized shrunk matrix of a batch and clusters the words using KMeans\n","    and returns the dataframe with each word assigned a relevant cluster id\"\"\"\n","     \n","    #as mentioned earlier, since our last batch would contain just around 1K texts hence it would have less\n","    # words and less diversity. So we cluster that in a 2 groups instead of 10,\n","    # previously we clustered into 30 a number we found in our initial prototypes\n","    # but that generated way too many similar clouds in this case so let's try 10 this time.\n","          \n","    print(\"\\tClustering words into groups...\")\n","    if batch_num != 24:\n","        cluster_model = KMeans(n_clusters=10)\n","        clusters = cluster_model.fit_predict(shrunk_norm_matrix)\n","        # we are using Z to make the plural in clusters, more apparent and more easily distinguishable\n","        clusterZ_df = pd.DataFrame({'Index': range(clusters.size), 'Cluster': clusters})\n","    else:\n","        cluster_model = KMeans(n_clusters=3)\n","        clusters = cluster_model.fit_predict(shrunk_norm_matrix)\n","        clusterZ_df = pd.DataFrame({'Index': range(clusters.size), 'Cluster': clusters})\n","    print(\"\\t\\tSuccessfully Clustered!\")\n","    return clusterZ_df\n","\n","# -------------\n","\n","for batch_num, batch in tqdm(enumerate(articles_dataset)):\n","    \n","    print(f\"\\nProcessing batch {batch_num+1} / {total_batches}\")\n","    \n","    # converts the tf object into numpy since we're accustomed ot numpy and pandas workflow\n","    batch = batch.numpy()\n","    \n","    # TODO: i- implement zipping the whole base output folder\n","    #       ii- save vectorize matrix for each cluster in a file to later read that in\n","    #           browser and use that to compute the user entered word's similarity with the cluster\n","    # now that i think about it, there's no way to calculate similarity with mere dot product between\n","    # a single word vector and vector of all the words in the given space or word cloud.\n","    # i mean sure, we can measure similarity between two sentences but apply the same method for a\n","    # sentence and a word doesn't seem like would work.\n","    \n","    # make directories to neatly organize our output files\n","    # also would be a lot easier to download later\n","    print(\"\\tMaking directories...\")\n","    batch_dir = base_dir / f\"batch{batch_num}\"\n","    cluster_words_dir = batch_dir / \"cluster_words\"\n","    cluster_clouds_dir = batch_dir / \"cluster_clouds\"   \n","    os.makedirs(cluster_words_dir, exist_ok=True)\n","    os.makedirs(cluster_clouds_dir, exist_ok=True)\n","    print(\"\\t\\tSuccessfully created required directories.\")\n","    \n","    # calculate the words, tfidf_matrix and sorted words df by calling the vectorizeX function\n","    print(\"\\tPerforming vectorization x...\")\n","    words, tfidf_matrix, words_tfidf_df, sorted_words_tfidf_df = vectorizeX(batch)\n","    print(\"\\t\\tSuccessfully vectorized x.\")\n","    \n","    print(f\"\\tTotal Words -> {len(words)}\")\n","    \n","    filename = batch_dir / f\"words_summed_tfidf_batch_{batch_num}.csv\"\n","    print(f\"\\tSaving {filename} to disk...\")\n","    \n","    filename = batch_dir / f\"sorted_words_summed_tfidf_batch_{batch_num}.csv\"\n","    print(f\"\\tSaving {filename} to disk...\")\n","    sorted_words_tfidf_df.to_csv(f\"{filename}\", index=False)\n","\n","    \n","    print(\"\\tApplying SVD...\")\n","    shrunk_matrix = TruncatedSVD(n_components=100).fit_transform(tfidf_matrix)\n","    print(\"\\t\\tSuccessfully applied SVD.\")\n","    \n","    # normalize the matrix\n","    print(\"\\tNormalizing shrunk matrix...\")\n","    shrunk_norm_matrix = normalize(shrunk_matrix)\n","    # norm(shrunk_norm_matrix[0])\n","    print(\"\\t\\tTarget normalized.\")\n","    \n","\n","    clusterZ_df = clusterItUp(shrunk_norm_matrix, batch_num=batch_num)\n","\n","    # though clusters file and summed tfidf file would pretty much contain the same words\n","    # with ONLY DIFFERENCE being that this cluster file would associate each word with its\n","    #cluster id. but we are saving it anyway.\n","    filename = batch_dir / f\"clustered_groups_batch_{batch_num}.csv\"\n","    clusterZ_df.to_csv(filename, index=False)\n","    # making a list of clustered groups for further manipulation\n","    cluster_groups = [df_cluster for _, df_cluster in clusterZ_df.groupby(\"Cluster\")]\n","#     len(cluster_groups)\n","    \n","    # the number of words we want in the word cloud image.\n","    # 15 seems to work well. But obviously you can change to whatever you want.\n","    max_words = 15\n","    \n","    # making a copy of clustered groups list so as to avoid accidently changing its elements\n","    cluster_groups_cp = cluster_groups[:]\n","    \n","    total_groups = len(cluster_groups_cp)\n","    \n","    print(f\"\\tGenerating word cloud images for clusters... \")\n","    for i in tqdm(range(total_groups)):\n","        cluster_df = cluster_groups_cp[i]\n","        wordcloud_image = cluster_to_cloud(cluster_df, cluster_num=i, \n","                                           words_list=words, batch_num=batch_num, \n","                                           save_dir=cluster_words_dir)\n","        \n","        filename = cluster_clouds_dir / f\"cluster_{i}_cloud_batch_{batch_num}.png\"\n","        wordcloud_image.to_file(filename)\n","        \n","#         if (i+1)%10==0:\n","#             print(f\"\\t\\t{i+1} of {total_groups} word clouds generated...\")\n","    \n","    print(f\"\\tYay! Everything went well for batch {batch_num}. Onto the next one!\\n\")\n","    \n","    print(\"\\tClearning up memory for next iteration so we dont run out of memory...\")\n","    del batch, words, tfidf_matrix, words_tfidf_df, sorted_words_tfidf_df, shrunk_matrix, clusterZ_df, cluster_groups, cluster_groups_cp\n","    gc.collect()\n","\n","    # for the test run, we're gonna run this loop for just once, hence we break here.\n","    # but before we break we'll zip the batch folder for easy download. BUT BUT BUT\n","    # once tested, we'll make archive of the base_dir and not batch dir\n","    # so that we can download the whole base_dir and not the batch dir.\n","#     shutil.make_archive(base_dir / \"base_output\", \"zip\", base_dir)\n","#     break\n","\n","# Zip up the whole output folder\n","shutil.make_archive(root_dir / \"output\", \"zip\", base_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"9b16f958606a7247fd2ba2750d9cad997c4b7c59ceec8c9b087db87db2a39d64"}}},"nbformat":4,"nbformat_minor":4}
