{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom numpy.linalg import norm\nfrom sklearn.preprocessing import normalize\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom wordcloud import WordCloud\nimport os\nimport shutil\nimport pathlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-15T17:19:26.178174Z","iopub.execute_input":"2022-06-15T17:19:26.179061Z","iopub.status.idle":"2022-06-15T17:19:31.98013Z","shell.execute_reply.started":"2022-06-15T17:19:26.178624Z","shell.execute_reply":"2022-06-15T17:19:31.97933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dir = pathlib.Path(\"/kaggle/working/output/\")\nos.makedirs(base_dir)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:19:34.245946Z","iopub.execute_input":"2022-06-15T17:19:34.246594Z","iopub.status.idle":"2022-06-15T17:19:34.253295Z","shell.execute_reply.started":"2022-06-15T17:19:34.246553Z","shell.execute_reply":"2022-06-15T17:19:34.252377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# array = np.arange(100)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T13:15:41.239081Z","iopub.execute_input":"2022-06-15T13:15:41.239515Z","iopub.status.idle":"2022-06-15T13:15:41.244214Z","shell.execute_reply.started":"2022-06-15T13:15:41.239479Z","shell.execute_reply":"2022-06-15T13:15:41.243042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset = tf.data.Dataset.from_tensor_slices(array)\n# dataset = dataset.batch(10)\n# for i, batch in enumerate(dataset):\n#     print(f\"{i}: {batch.numpy()}\")\n# print(len(dataset))","metadata":{"execution":{"iopub.status.busy":"2022-06-15T13:35:26.003039Z","iopub.execute_input":"2022-06-15T13:35:26.003463Z","iopub.status.idle":"2022-06-15T13:35:26.037739Z","shell.execute_reply.started":"2022-06-15T13:35:26.003419Z","shell.execute_reply":"2022-06-15T13:35:26.03584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all_batches = []\n# for i in range(10):\n#     batch = np.random.choice(array, size=10, replace=False)\n#     all_batches.extend(batch)\n#     print(f\"{i}th iter: {batch}\")\n# print(f\"Total unique elements sampled: {len(np.unique(np.array(all_batches), return_counts=False))}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T13:22:02.3069Z","iopub.status.idle":"2022-06-15T13:22:02.308017Z","shell.execute_reply.started":"2022-06-15T13:22:02.307695Z","shell.execute_reply":"2022-06-15T13:22:02.307724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"articles_dataset = tf.data.Dataset.from_tensor_slices((pd.read_csv(\"/kaggle/input/medium-articles/medium_articles.csv\")['text']).values)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T13:32:26.881195Z","iopub.execute_input":"2022-06-15T13:32:26.881657Z","iopub.status.idle":"2022-06-15T13:32:47.521753Z","shell.execute_reply.started":"2022-06-15T13:32:26.881622Z","shell.execute_reply":"2022-06-15T13:32:47.492908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"articles_dataset = articles_dataset.batch(9000)\nprint(len(articles_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-06-15T13:35:10.787384Z","iopub.execute_input":"2022-06-15T13:35:10.787812Z","iopub.status.idle":"2022-06-15T13:35:10.794337Z","shell.execute_reply.started":"2022-06-15T13:35:10.787778Z","shell.execute_reply":"2022-06-15T13:35:10.793332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We've got 22 batches of length 9000 each but we have about 190K or 190K+ artciles so it's obvious that the last batch would be around ~1K texts, which may not be suitable for us, but generate word clouds from it anyway.","metadata":{}},{"cell_type":"code","source":"def rank_words_by_tfidf(indices, words_list):\n    \"\"\"Ranks the words, specified by indices which are sent in by \"cluster_to_cloud\"\n    function. Ranking is based on the summed tfidf score \"\"\"\n    \n    summed_tfidf = np.asarray(tfidf_matrix[indices].sum(axis=0))\n    data = {\"Words\": words_list,\n           \"Summed_TFIDF\": summed_tfidf}\n    return pd.DataFrame(data).sort_values(\"Summed_TFIDF\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T13:48:30.209788Z","iopub.execute_input":"2022-06-15T13:48:30.210258Z","iopub.status.idle":"2022-06-15T13:48:30.21681Z","shell.execute_reply.started":"2022-06-15T13:48:30.210219Z","shell.execute_reply":"2022-06-15T13:48:30.215736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cluster_to_cloud(df_cluster, max_words=15, cluster_num=0, batch_num=0):\n    \"\"\"Generates a word cloud image using the top 15 words \n    (which are ranked by their tfidf score) in the given cluster\"\"\"\n    \n    indices = df_cluster.Index.values\n    df_ranked_words_all = rank_words_by_tfidf(indices)\n    df_ranked_words_in_cloud = df_ranked_words_all[:max_words]\n    df_ranked_words_remaining = df_ranked_words_all[max_words:]\n    \n    df_ranked_words_remaining.to_csv(f\"cluster_{cluster_num}_words_batch_{batch_num}.csv\")\n    words_to_score = {word:score\n                     for word, score in df_ranked_words_in_cloud.values}    \n    cloud_generator = WordCloud(background_color=\"white\",\n                               random_state=1, width=2000, height=1000)\n    wordcloud_image = cloud_generator.fit_words(words_to_score)\n    return wordcloud_image","metadata":{"execution":{"iopub.status.busy":"2022-06-15T13:51:21.431417Z","iopub.execute_input":"2022-06-15T13:51:21.431826Z","iopub.status.idle":"2022-06-15T13:51:21.439803Z","shell.execute_reply.started":"2022-06-15T13:51:21.431795Z","shell.execute_reply":"2022-06-15T13:51:21.438874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vectorizeX(batch, batch_num=0):\n    \"\"\"Vectorizes the texts,generates the TFIDF matrix\n    and returns TFIDF matrix, words, and sorted words TFIDF dataframe.\n    X in the function names stands for eXtra, as it performs and returns some extra things\n    also in all honesty, it's more because it's sounds cool this way. No judging, okay?\"\"\"\n    \n    tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n    tfidf_matrix = tfidf_vectorizer.fit_transform(batch).toarray()\n    words = tfidf_vectorizer.get_feature_names()\n    words_tfidf_df = pd.DataFrame({\"Words\": words, \"Summed_TFIDF\": tfidf_matrix.sum(axis=0)})\n    sorted_words_tfidf_df = words_tfidf_df.sort_values(by=\"Summed_TFIDF\", ascending=False)\n    \n    return words, tfidf_matrix, sorted_words_tfidf_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clusterItUp(batch, batch_num=0):\n    \"\"\"Takes the normalized shrunk matrix of a batch and clusters the words using KMeans\n    and returns the dataframe with each word assigned a relevant cluster id\"\"\"\n     \n    #as mentioned earlier, since our last batch would contain just around 1K texts hence it would have less\n    # words and less diversity. So we cluster that in a 3 groups instead of 30 which by the way is the number of groups\n    # we found in our ealier extensive testing and prototyping.\n          \n    print(\"/tClustering words into groups...\")\n    if batch_num != 21:\n        cluster_model = KMeans(n_clusters=30)\n        clusters = cluster_model.fit_predict(shrunk_norm_matrix)\n        # we are using Z to make the plural in clusters, more apparent and more easily distinguishable\n        clusterZ_df = pd.DataFrame({'Index': range(clusters.size), 'Cluster': clusters})\n    else:\n        cluster_model = KMeans(n_clusters=3)\n        clusters = cluster_model.fit_predict(shrunk_norm_matrix)\n        clusterZ_df = pd.DataFrame({'Index': range(clusters.size), 'Cluster': clusters})\n    print(\"\\t\\tSuccessfully Clustered!\")\n    return clusters_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch_num, batch in enumerate(artciles_dataset):\n    \n    print(f\"\\nProcessing batch {batch_num}...)\n    \n    # TODO: i- implement zipping the whole base output folder\n    #       ii- save vectorize matrix for each cluster in a file to later read that in\n    #           browser and use that to compute the user entered word's similarity with the cluster\n    # now that i think about it, there's no way to calculate similarity with mere dot product between\n    # a single word vector and vector of all the words in the given space or word cloud.\n    # i mean sure, we can measure similarity between two sentences but apply the same method for a\n    # sentence and a word doesn't seem like would work.\n    \n    # make directories to neatly organize our output files\n    # also would be a lot easier to download later\n    batch_dir = base_dir / f\"batch{batch_num}\"\n    cluster_words_dir = batch_dir / \"cluster_words\"\n    cluster_clouds_dir = batch_dir / \"cluster_clouds\"\n    os.makedirs(cluster_words_dir)\n    os.makedirs(cluster_clouds_dir)\n\n\n    print(f\"\\tTotal Words -> {len(words)}\"\")\n    \n    # calculate the words, tfidf_matrix and sorted words df by calling the vectorizeX function\n    words, tfidf_matrix, sorted_words_tfidf_df = vectorizeX(batch, batch_num=batch_num)\n    \n    filename = batch_dir / f\"sorted_words_summed_tfidf_batch_{batch_num}.csv\"\n    sorted_words_tfidf_df.to_csv(f\"{filename}\", index=False)\n\n    \n    print(\"\\tApplying SVD...\")\n    shrunk_matrix = TruncatedSVD(n_components=100).fit_transform(tfidf_matrix)\n    # normalize the matrix\n    shrunk_norm_matrix = normalize(shrunk_matrix)\n    print(\"\\t\\tSuccessfully applied SVD.\")\n    # norm(shrunk_norm_matrix[0])\n    \n          \n    clusterZ_df = clusterItUp(shrunk_norm_matrix, batch_num=batch_num)\n    # making a list of clustered groups for further manipulation\n    cluster_groups = [df_cluster for _, df_cluster in clusterZ_df.groupby(\"Cluster\")]\n#     len(cluster_groups)\n    \n    # the number of words we want in the word cloud image.\n    # 15 seems to work well. But obviously you can change to whatever you want.\n    max_words = 15\n    \n    # making a copy of clustered groups list so as to avoid accidently changing its elements\n    cluster_groups_cp = cluster_groups[:]\n    \n    total_groups = len(cluster_groups_cp)\n    \n    print(f\"\\tGenerating word cloud images for clusters... \")\n    for i in range(total_groups):\n        cluster_df = cluster_groups_cp[i]\n        wordcloud_image = cluster_to_cloud(cluster_df, cluster_num=i, batch_num=batch_num)\n        wordcloud_image.to_file(f\"cluster_{i}_cloud.png\")\n        \n        if i+1%10==0:\n          print(f\"\\t\\t{i+1} of {total_groups} word clouds generated...\")\n    \n    print(f\"\\tYay! Everything went well for batch {batch_num}. Onto the next one!\\n\")\n    return","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting a quick to see what we're dealing with\n#articles_df.describe()\n#articles_df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# limited out analysis to 10K texts due to kaggle's memory limitations that arise while generating tfidf vectorizations\n# we make the selection randomly for following reasons\n#     i- The dataset provider mentions that they scraped data using web crawlers that followed links\n#        from within the article (author and other existing links)\n#        hence it's a fair assumption that the consecutive articles would be similar in theme\n#        so we're selecting randomly.\n\narticles_random_10K_texts = np.random.choice(np.asarray(articles_df['text']), 10000)\nprint(\"random: \", articles_random_10K_texts.shape)\n# articles_first_100_texts = np.asarray(articles_df['text'][:100])\n# print(\"sequential: \", articles_first_100_texts.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T04:48:11.610665Z","iopub.execute_input":"2022-06-03T04:48:11.611179Z","iopub.status.idle":"2022-06-03T04:48:11.630908Z","shell.execute_reply.started":"2022-06-03T04:48:11.611139Z","shell.execute_reply":"2022-06-03T04:48:11.629177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:14:48.656688Z","iopub.execute_input":"2022-06-04T11:14:48.657138Z","iopub.status.idle":"2022-06-04T11:14:49.653018Z","shell.execute_reply.started":"2022-06-04T11:14:48.657085Z","shell.execute_reply":"2022-06-04T11:14:49.652125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# texts_10K_list = list(articles_10K_texts)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T04:48:23.206531Z","iopub.execute_input":"2022-06-03T04:48:23.207392Z","iopub.status.idle":"2022-06-03T04:48:23.308082Z","shell.execute_reply.started":"2022-06-03T04:48:23.207308Z","shell.execute_reply":"2022-06-03T04:48:23.30664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\ntfidf_matrix = tfidf_vectorizer.fit_transform(articles_df).toarray()\nwords = tfidf_vectorizer.get_feature_names()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:14:55.07819Z","iopub.execute_input":"2022-06-04T11:14:55.079141Z","iopub.status.idle":"2022-06-04T11:15:07.029778Z","shell.execute_reply.started":"2022-06-04T11:14:55.079092Z","shell.execute_reply":"2022-06-04T11:15:07.02885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_tfidf_df = pd.DataFrame({\"Words\": words, \"Summed_TFIDF\": tfidf_matrix.sum(axis=0)})\nsorted_words_tfidf_df = words_tfidf_df.sort_values(by=\"Summed_TFIDF\", ascending=False)\nsorted_words_tfidf_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T04:43:35.239279Z","iopub.execute_input":"2022-06-03T04:43:35.239847Z","iopub.status.idle":"2022-06-03T04:43:36.108759Z","shell.execute_reply.started":"2022-06-03T04:43:35.239808Z","shell.execute_reply":"2022-06-03T04:43:36.107909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def not_a_number(word):\n#     try:\n#         num = int(word)\n#         print(\"it IS a number, the number is: \", num)\n#         return False\n#     except:\n#         print(\"its NOT a number the word is: \", word)\n#         return True","metadata":{"execution":{"iopub.status.busy":"2022-06-03T04:06:49.611773Z","iopub.execute_input":"2022-06-03T04:06:49.612156Z","iopub.status.idle":"2022-06-03T04:06:49.616583Z","shell.execute_reply.started":"2022-06-03T04:06:49.612126Z","shell.execute_reply":"2022-06-03T04:06:49.615671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# words_series = pd.Series()\n\n# non_zero_words_to_print = 0\n# for word in words:\n#     if not in words:\n#         print(word)\n#         non_zero_words_to_print +=1\n#     if non_zero_words_to_print == 5:\n#         break","metadata":{"execution":{"iopub.status.busy":"2022-06-03T04:01:46.740198Z","iopub.execute_input":"2022-06-03T04:01:46.740926Z","iopub.status.idle":"2022-06-03T04:01:46.748828Z","shell.execute_reply.started":"2022-06-03T04:01:46.74088Z","shell.execute_reply":"2022-06-03T04:01:46.748011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(words))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T04:49:12.011313Z","iopub.execute_input":"2022-06-03T04:49:12.011773Z","iopub.status.idle":"2022-06-03T04:49:12.016537Z","shell.execute_reply.started":"2022-06-03T04:49:12.011735Z","shell.execute_reply":"2022-06-03T04:49:12.015756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #nvm\n# from numpy.linalg import norm\n# norm(df['Summed Tfidf'].values)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T12:43:04.743854Z","iopub.execute_input":"2022-06-02T12:43:04.744414Z","iopub.status.idle":"2022-06-02T12:43:04.764014Z","shell.execute_reply.started":"2022-06-02T12:43:04.744375Z","shell.execute_reply":"2022-06-02T12:43:04.762997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:15:17.40372Z","iopub.execute_input":"2022-06-04T11:15:17.40432Z","iopub.status.idle":"2022-06-04T11:15:17.557987Z","shell.execute_reply.started":"2022-06-04T11:15:17.40428Z","shell.execute_reply":"2022-06-04T11:15:17.557284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shrunk_matrix = TruncatedSVD(n_components=100).fit_transform(tfidf_matrix)\nshrunk_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:15:18.383394Z","iopub.execute_input":"2022-06-04T11:15:18.384033Z","iopub.status.idle":"2022-06-04T11:16:34.358803Z","shell.execute_reply.started":"2022-06-04T11:15:18.383996Z","shell.execute_reply":"2022-06-04T11:16:34.358115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy.linalg import norm\nfrom sklearn.preprocessing import normalize\nshrunk_norm_matrix = normalize(shrunk_matrix)\nnorm(shrunk_norm_matrix[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:17:32.596382Z","iopub.execute_input":"2022-06-04T11:17:32.596844Z","iopub.status.idle":"2022-06-04T11:17:32.609878Z","shell.execute_reply.started":"2022-06-04T11:17:32.596805Z","shell.execute_reply":"2022-06-04T11:17:32.60912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#no need to compute for this task\n#cosine_similarity = shrunk_norm_matrix @ shrunk_norm_matrix.T","metadata":{"execution":{"iopub.status.busy":"2022-06-02T11:34:24.608609Z","iopub.execute_input":"2022-06-02T11:34:24.609249Z","iopub.status.idle":"2022-06-02T11:34:25.740024Z","shell.execute_reply.started":"2022-06-02T11:34:24.609193Z","shell.execute_reply":"2022-06-02T11:34:25.738803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.cluster import MiniBatchKMeans","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:17:43.867324Z","iopub.execute_input":"2022-06-04T11:17:43.868088Z","iopub.status.idle":"2022-06-04T11:17:43.971832Z","shell.execute_reply.started":"2022-06-04T11:17:43.868036Z","shell.execute_reply":"2022-06-04T11:17:43.97111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_values = range(1,101)\nintertia_values = [MiniBatchKMeans(k).fit(shrunk_norm_matrix).inertia_\n                  for k in k_values]","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:17:49.30257Z","iopub.execute_input":"2022-06-04T11:17:49.302999Z","iopub.status.idle":"2022-06-04T11:18:38.738163Z","shell.execute_reply.started":"2022-06-04T11:17:49.30296Z","shell.execute_reply":"2022-06-04T11:18:38.736993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(k_values, intertia_values)\nplt.xlabel(\"K\")\nplt.ylabel(\"Inertia\")\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:18:44.109643Z","iopub.execute_input":"2022-06-04T11:18:44.110609Z","iopub.status.idle":"2022-06-04T11:18:44.340616Z","shell.execute_reply.started":"2022-06-04T11:18:44.110564Z","shell.execute_reply":"2022-06-04T11:18:44.339454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\ncluster_model = KMeans(n_clusters=30)\nclusters = cluster_model.fit_predict(shrunk_norm_matrix)\ndf = pd.DataFrame({'Index': range(clusters.size), 'Cluster': clusters})","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:19:30.949648Z","iopub.execute_input":"2022-06-04T11:19:30.950137Z","iopub.status.idle":"2022-06-04T11:19:34.119306Z","shell.execute_reply.started":"2022-06-04T11:19:30.950097Z","shell.execute_reply":"2022-06-04T11:19:34.118415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[:10]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T12:12:26.433933Z","iopub.execute_input":"2022-06-02T12:12:26.434423Z","iopub.status.idle":"2022-06-02T12:12:26.450112Z","shell.execute_reply.started":"2022-06-02T12:12:26.434388Z","shell.execute_reply":"2022-06-02T12:12:26.448835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(words)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T05:13:04.828255Z","iopub.execute_input":"2022-06-03T05:13:04.829148Z","iopub.status.idle":"2022-06-03T05:13:04.836362Z","shell.execute_reply.started":"2022-06-03T05:13:04.829084Z","shell.execute_reply":"2022-06-03T05:13:04.835167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rank_words_by_tfidf(indices, words_list = words):\n#     print(f\"\\n-->[func RWBT] Indices received: {indices}\")\n    summed_tfidf = np.asarray(tfidf_matrix[indices].sum(axis=0))\n#     print(f\"\\n-->[func RWBT] summed_tfidf calcutated: {summed_tfidf}\")\n    data = {\"Words\": words_list,\n           \"Summed_TFIDF\": summed_tfidf}\n    return pd.DataFrame(data).sort_values(\"Summed_TFIDF\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:19:57.537519Z","iopub.execute_input":"2022-06-04T11:19:57.538079Z","iopub.status.idle":"2022-06-04T11:19:57.542868Z","shell.execute_reply.started":"2022-06-04T11:19:57.538024Z","shell.execute_reply":"2022-06-04T11:19:57.542154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_dict = {'a': 1, 'b': 2, 'c':3, 'd': 4}\nlist(sample_dict.keys())[:2]","metadata":{"execution":{"iopub.status.busy":"2022-06-15T13:43:51.658504Z","iopub.execute_input":"2022-06-15T13:43:51.658939Z","iopub.status.idle":"2022-06-15T13:43:51.666401Z","shell.execute_reply.started":"2022-06-15T13:43:51.658903Z","shell.execute_reply":"2022-06-15T13:43:51.665415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_and_summed_tfidf_matrix_df = pd.DataFrame({\"Words\": words,\n                                                \"Summed_TFIDF\": tfidf_matrix.sum(axis=0)})\nwords_and_summed_tfidf_matrix_df.to_csv(\"words_summed_tfidf_medium_random_8K_texts.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T06:41:01.058587Z","iopub.execute_input":"2022-06-03T06:41:01.059075Z","iopub.status.idle":"2022-06-03T06:41:01.985237Z","shell.execute_reply.started":"2022-06-03T06:41:01.059032Z","shell.execute_reply":"2022-06-03T06:41:01.984166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_and_summed_tfidf_matrix_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-03T06:43:30.835848Z","iopub.execute_input":"2022-06-03T06:43:30.836437Z","iopub.status.idle":"2022-06-03T06:43:30.844456Z","shell.execute_reply.started":"2022-06-03T06:43:30.836387Z","shell.execute_reply":"2022-06-03T06:43:30.843587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:20:10.962479Z","iopub.execute_input":"2022-06-04T11:20:10.962902Z","iopub.status.idle":"2022-06-04T11:20:11.003793Z","shell.execute_reply.started":"2022-06-04T11:20:10.96286Z","shell.execute_reply":"2022-06-04T11:20:11.002826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cluster_to_cloud(df_cluster, max_words=15, cluster_num=0):\n    indices = df_cluster.Index.values\n    df_ranked_words_all = rank_words_by_tfidf(indices)\n    df_ranked_words_in_cloud = df_ranked_words_all[:max_words]\n    df_ranked_words_remaining = df_ranked_words_all[max_words:]\n    df_ranked_words_remaining.to_csv(f\"cluster_{cluster_num}_words.csv\")\n    words_to_score = {word:score\n                     for word, score in df_ranked_words_in_cloud.values}    \n    cloud_generator = WordCloud(background_color=\"white\",\n                               random_state=1, width=2000, height=1000)\n    wordcloud_image = cloud_generator.fit_words(words_to_score)\n    return wordcloud_image","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:07:39.87764Z","iopub.execute_input":"2022-06-04T12:07:39.878734Z","iopub.status.idle":"2022-06-04T12:07:39.885566Z","shell.execute_reply.started":"2022-06-04T12:07:39.878668Z","shell.execute_reply":"2022-06-04T12:07:39.884631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_groups = [df_cluster for _, df_cluster in df.groupby(\"Cluster\")]\nlen(cluster_groups)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:20:41.28355Z","iopub.execute_input":"2022-06-04T11:20:41.284013Z","iopub.status.idle":"2022-06-04T11:20:41.304384Z","shell.execute_reply.started":"2022-06-04T11:20:41.283977Z","shell.execute_reply":"2022-06-04T11:20:41.303348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating word clouds along with list of words in the same cluster\n# for our game \"Predict the word in the cloud\"\n\nmax_words = 15\ncluster_groups_cp = cluster_groups[:]\n# plt.figure(figsize=(10,6), dpi=300)\ntotal_groups = len(cluster_groups_cp)\nfor i in range(total_groups):\n    print(f\"Processing cluster {i} | {round(((i+1)/(total_groups+1))*100, 2)}% done.\")\n    cluster_df = cluster_groups_cp[i]\n    wordcloud_image = cluster_to_cloud(cluster_df, cluster_num=i)\n    wordcloud_image.to_file(f\"cluster_{i}_cloud.png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:11:33.965411Z","iopub.execute_input":"2022-06-04T12:11:33.965906Z","iopub.status.idle":"2022-06-04T12:12:34.626446Z","shell.execute_reply.started":"2022-06-04T12:11:33.965864Z","shell.execute_reply":"2022-06-04T12:12:34.62553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows, cols = 5, 2\nfigure, axes = plt.subplots(rows, cols, figsize=(15,30))\ncluster_groups_copy = cluster_groups[:]\ni = 0\nfor r in range(rows):\n    for c in range(cols):\n        df_cluster = cluster_groups_copy[i]\n#         print(f\"\\n\\n Sending cluster: {df_cluster.head(3)} \\n\\n\")\n        wordcloud_image = cluster_to_cloud(df_cluster)\n        ax = axes[r][c]\n        ax.imshow(wordcloud_image, interpolation='bilinear')\n        ax.set_title(f\"Cluster {df_cluster.Cluster.iloc[0]}\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        i+=1\n        if i == 10:\n            break\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T11:20:53.550219Z","iopub.execute_input":"2022-06-04T11:20:53.550643Z","iopub.status.idle":"2022-06-04T11:20:56.634718Z","shell.execute_reply.started":"2022-06-04T11:20:53.550607Z","shell.execute_reply":"2022-06-04T11:20:56.634014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"medium_random_8K_texts_clusters.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T06:24:30.834461Z","iopub.execute_input":"2022-06-03T06:24:30.834896Z","iopub.status.idle":"2022-06-03T06:24:30.858443Z","shell.execute_reply.started":"2022-06-03T06:24:30.834862Z","shell.execute_reply":"2022-06-03T06:24:30.857477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}